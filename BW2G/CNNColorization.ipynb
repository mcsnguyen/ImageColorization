{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CNNColorization.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"code_folding":[0],"colab_type":"code","id":"1Cuc0HZWbz43","colab":{}},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557556028701,"user_tz":420,"elapsed":2199,"user":{"displayName":"Michael Nguyen","photoUrl":"","userId":"00567827782916811779"}},"id":"6fr5ptOC4DnI","outputId":"ba87bbc6-8717-4997-b562-8d985516a9f3","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!pwd"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2ruGBm3zcY0I","colab":{}},"source":["cd drive/My Drive/BW2G"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RFFlNOkjVIW","colab_type":"code","colab":{}},"source":["!pip install numpy==1.16.1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1557556034116,"user_tz":420,"elapsed":2792,"user":{"displayName":"Michael Nguyen","photoUrl":"","userId":"00567827782916811779"}},"id":"fN81I8nobihZ","outputId":"19d97a75-f0ce-46da-cbbd-7fba9fd542d4","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","import cv2\n","import time\n","import h5py\n","import keras\n","import shutil\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","\n","from PIL import Image\n","from keras.models import Sequential, Model, load_model\n","from keras.layers import Input, InputLayer, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Conv2DTranspose, Dropout, BatchNormalization\n","from keras.callbacks import EarlyStopping, TensorBoard\n","from keras import regularizers, losses, optimizers\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"i3f9Cvmybihg","colab":{}},"source":["dim_size = 256\n","l_channel = 1\n","ab_channel = 2\n","\n","dir_size = 9601\n","\n","dataset_path = 'images/0'\n","dataset_test_path = 'images/1'\n","\n","resized_train_path = 'squared_images/flowers/'\n","resized_test_path = 'squared_images/test/'\n","\n","train_path = 'bw_images/'\n","train_path_v2 = 'blur_images/'\n","validate_path = 'gray_images/'\n","\n","test_train_path = 'bw_test_images/'\n","test_val_path = 'gray_test_images/'\n","\n","# Hyperparameters\n","models_path = 'saved_parameters/'\n","\n","saved_model = 'saved_model-adam-mse.h5'\n","saved_weights = 'saved_weights.h5'\n","\n","saved_data = 'loaded_images_bin2gr_gr2rgb.npz'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[],"colab_type":"code","id":"B9oUf1h4bihj","scrolled":true,"colab":{}},"source":["# Create directory\n","def create_dir(folder_name):\n","    folder = os.path.join(folder_name)\n","    if not os.path.exists(folder):\n","        os.mkdir(folder)\n","    return folder\n","                          \n","def save_path(dir_path, file, appended_name):\n","    file_base = os.path.basename(file)\n","    file_name, file_ext = os.path.splitext(file_base)   \n","    return dir_path + file_name + appended_name + file_ext\n","\n","def file_count(dir_path):\n","    counter = 0\n","    for file in os.listdir(dir_path):\n","        counter += 1\n","    return counter\n","\n","#-------------------------------------------------------------------------------\n","# Image Preprocessing\n","# Edge Detection Preprocessing\n","def blur_images(rgb_arr):\n","    blur_arr = []\n","    for i in range(0, len(rgb_arr)):\n","        blur = cv2.GaussianBlur(rgb_arr[i], (3,3), 0)\n","        blur_arr.append(blur)\n","    return blur_arr\n","\n","def get_edges(rgb_arr):\n","    edge_arr = []\n","    for i in range(0, len(rgb_arr)):\n","        grayscale = cv2.cvtColor(rgb_arr[i], cv2.COLOR_BGR2GRAY)\n","        x_edges = cv2.Sobel(grayscale, cv2.CV_16S, 1, 0)\n","        y_edges = cv2.Sobel(grayscale, cv2.CV_16S, 0, 1)\n","        \n","        # Remove negative values\n","        x_abs = cv2.convertScaleAbs(x_edges)\n","        y_abs = cv2.convertScaleAbs(y_edges)\n","        \n","        # Edges are white, background is black\n","        detected_edges = cv2.addWeighted(x_abs, 0.5, y_abs, 0.5, 0)\n","        # Prepare colorspaces, Edges are black, background is white\n","        thresh, inverted_colors = cv2.threshold(detected_edges, 50, 255, cv2.THRESH_BINARY_INV)\n","        edge_arr.append(inverted_colors)\n","    return edge_arr\n","\n","def RBG2LAB(rgb_np):\n","    lab_arr = []\n","    for i in range(rgb_np.shape[0]):\n","        lab_arr.append(cv2.cvtColor(rgb_np[i], RGB2LAB))\n","    return np.array(lab_arr)\n","\n","# Resize Image\n","# Creates a white image and pastes data into white image\n","def square_images(dataset_path, size):\n","    dir_path = create_dir('squared_images/')\n","    for file in os.listdir(dataset_path):\n","        image = Image.open(os.path.join(dataset_path, file))\n","        width, height = image.size\n","        if(width != height and width != size):\n","            squared_image = image.resize((size,size), Image.LANCZOS)\n","            #squared_image.paste(image)\n","            squared_image.save(save_path(dir_path, file, '_SQ'))\n","\n","#-------------------------------------------------------------------------------\n","# Load in Preprocessed Images\n","def load_saved(saved_data):\n","    data = np.load(saved_data)\n","    return data['BIN'], data['GR']#, data['RGB'], data['PR_GR'], data['PR_RGB']\n","\n","def save_loaded(save_dir, save_name, binary=None, grayscale=None, rgb=None, predicted_gray=None, predicted_rgb=None, **kwargs):\n","    save_dest = create_dir(save_dir)\n","    save_dest = os.path.join(save_dir, save_name)\n","    #np.savez(save_dest, BIN=binary, GR=grayscale, RGB=rgb, PR_GR=predicted_gray, PR_RGB=predicted_rgb)\n","    p.savez(save_dest, BIN=binary, GR=grayscale)\n","    \n","def load_images(dataset_path, size=None):\n","    if size is None:\n","        size = file_count(dataset_path)\n","        #size = dir_size\n","    img_arr = []\n","    name_arr = []\n","    \n","    for file, i in zip(os.listdir(dataset_path), range(0, size)):\n","        name = os.path.splitext(os.path.basename(file))[0]\n","        img = cv2.imread(os.path.join(dataset_path, file))\n","        name_arr.append(name)\n","        img_arr.append(img)\n","    return name_arr, img_arr\n","    \n","def save_images(train_path, validate_path, names_arr, gray_arr, gray_tag, bw_arr, bw_tag):\n","    dir_path = create_dir(train_path)\n","    dir_path = create_dir(validate_path)\n","    \n","    gray_np = np.asarray(gray_arr)\n","    bw_np = np.asarray(bw_arr)\n","    \n","    for i in range(0, len(gray_arr)):\n","        gray_path = save_path(validate_path, names_arr[i], '-{}.jpg'.format(gray_tag))\n","        bw_path = save_path(train_path, names_arr[i], '-{}.jpg'.format(bw_tag))\n","        cv2.imwrite(gray_path, gray_np[i])\n","        cv2.imwrite(bw_path, bw_np[i])\n","    \n","def convert_RGB2GR(validate_path, img_arr):\n","    gray_arr = []\n","    grayscale_path = create_dir(validate_path)\n","    \n","    for i in range(0, len(img_arr)):\n","        grayscale = cv2.cvtColor(img_arr[i], cv2.COLOR_BGR2GRAY) \n","        gray_arr.append(grayscale)\n","    return gray_arr, np.array(gray_arr)\n","\n","def convert_BLUR2EDGE(train_path, rgb_arr):\n","    blur_path = create_dir(train_path)\n","    blur_rgb = blur_images(rgb_arr)\n","    edges = get_edges(blur_rgb)\n","    return edges, np.array(edges)\n"," \n","def load_model_data(source_path, train_path, validate_path, model_dir, save_name, load_train_size=None, **kwargs):\n","    img_names, loaded_RGB = load_images(source_path, load_train_size)\n","    \n","    loaded_GR, gray_np = convert_RGB2GR(validate_path, loaded_RGB)\n","    loaded_BW , bw_np = convert_BLUR2EDGE(train_path_v2, loaded_RGB)\n","    \n","    #save_images(train_path, validate_path, img_names, loaded_GR, 'GR', loaded_BW, 'BW')\n","    save_loaded(model_dir, save_name, binary=bw_np, grayscale=gray_np, rgb=np.array(loaded_RGB))\n","    return bw_np, gray_np, np.array(loaded_RGB)\n","  \n","    \n","#-------------------------------------------------------------------------------\n","def test_split(bw_arr, gray_arr, size):\n","    test_bw = []\n","    test_gray = []\n","    for count in range(len(bw_arr), len(bw_arr) - size, -1):\n","        test_bw.append(bw_arr[count])\n","        test_gray.append(gray_arr[count])\n","    \n","    test_bw_np = test_bw.array(test_bw)\n","    test_gray_np = test_gray.array(test_gray)\n","    return test_bw_np, test_gray_np\n","                                \n","# Load training and validating images with cv2 to capture channel dim\n","def load_binary_gray(dir_path, size=None):\n","    if size is None:\n","        #size = file_count(dataset_path)\n","        size = dir_size\n","    data_arr = []\n","    for file, count in zip(os.listdir(dir_path), range(0, size)):\n","        img_read = cv2.imread(os.path.join(dir_path, file), 0)\n","        img_read = np.array(img_read)\n","        data_arr.append(img_read)\n","    return data_arr\n","\n","def test_load(dir_path):\n","    data_arr = []\n","    counter = 0\n","    for file in sorted(os.listdir(dir_path)):\n","        img_read = cv2.imread(os.path.join(dir_path, file), 0)\n","        img_read = np.array(img_read)\n","        print(file)\n","        print(img_read.shape)\n","        data_arr.append(img_read)\n","        counter += 1\n","        if counter == 2:\n","            return data_arr\n","    return data_arr\n","\n","#-------------------------------------------------------------------------------\n","# Calculate epoch size to traverse all training data\n","def step_size(dir_path, batch_size):\n","    counter = 0\n","    for file in os.listdir(dir_path):\n","        if os.path.isfile(os.path.join(dir_path, file)):\n","            counter += 1\n","    return int(counter/batch_size)\n","\n","#-------------------------------------------------------------------------------\n","# ML Functions\n","def encoder(filters, kernel_size, stride_size, drop_rate, inputs):\n","    encode = Conv2D(filters, kernel_size, strides=stride_size, padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(inputs)\n","    encode = BatchNormalization()(encode)\n","    encode = Dropout(drop_rate)(encode)\n","    encode = Conv2D(filters, kernel_size, strides=stride_size, padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(0.01))(encode)\n","    encode = BatchNormalization()(encode)\n","    pool = MaxPooling2D((2,2), padding='same')(encode)\n","    return encode, pool\n","\n","def latent_space(filters, kernel_size, stride_size, inputs):\n","    latent = Conv2D(filters, kernel_size, strides=stride_size, padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(inputs)\n","    latent = Dropout(drop_rate)(latent)\n","    latent = BatchNormalization()(latent)\n","    latent = Conv2D(filters, kernel_size, strides=stride_size, padding = 'same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(latent)\n","    latent = BatchNormalization()(latent)\n","    return latent\n","\n","def decoder(filters, up_kernel, up_strides, de_kernel, de_strides, inputs, up_inputs):\n","    decode = Conv2DTranspose(filters, up_kernel, strides=up_strides, padding='same')(inputs)\n","    #decode = UpSampling2D((2,2))(inputs)\n","    up = Concatenate()([up_inputs, decode])\n","    decode = Conv2D(filters, de_kernel, strides=de_strides, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(up)\n","    decode = Dropout(drop_rate)(decode)\n","    decode = BatchNormalization()(decode)\n","    decode = Conv2D(filters, de_kernel, strides=de_strides, padding='same', activation='relu', kernel_regularizer=regularizers.l2(0.001))(decode)\n","    decode = BatchNormalization()(decode)\n","    return decode\n","\n","def autoencoder(train_shape, filters, kernel_sizes, stride_sizes, drop_rate, decoder_activation='sigmoid', **kwargs):\n","    input_shape = Input(shape=(train_shape))\n","\n","    encode1, pool1 = encoder(filters[0], kernel_sizes['encode'], stride_sizes['encode'], drop_rate, input_shape)\n","    encode2, pool2 = encoder(filters[1], kernel_sizes['encode'], stride_sizes['encode'], drop_rate, pool1)\n","    encode3, pool3 = encoder(filters[2], kernel_sizes['encode'], stride_sizes['encode'], drop_rate, pool2)\n","    encode4, pool4 = encoder(filters[3], kernel_sizes['encode'], stride_sizes['encode'], drop_rate, pool3)\n","    encode5, pool5 = encoder(filters[4], kernel_sizes['encode'], stride_sizes['encode'], drop_rate, pool4)\n","\n","    latent = latent_space(filters[5], en_kernel, en_strides, pool5)\n","\n","    decode1 = decoder(filters[4], kernel_sizes['upsample'], stride_sizes['upsample'], kernel_sizes['decode'], stride_sizes['decode'], latent, encode5)\n","    decode2 = decoder(filters[3], kernel_sizes['upsample'], stride_sizes['upsample'], kernel_sizes['decode'], stride_sizes['decode'], decode1, encode4)\n","    decode3 = decoder(filters[2], kernel_sizes['upsample'], stride_sizes['upsample'], kernel_sizes['decode'], stride_sizes['decode'], decode2, encode3)\n","    decode4 = decoder(filters[1], kernel_sizes['upsample'], stride_sizes['upsample'], kernel_sizes['decode'], stride_sizes['decode'], decode3, encode2)\n","    decode5 = decoder(filters[0], kernel_sizes['upsample'], stride_sizes['upsample'], kernel_sizes['decode'], stride_sizes['decode'], decode4, encode1)\n","\n","    output_shape = Conv2D(1, (1,1), activation='decoder_activation')(decode5)\n","\n","    auto = Model(inputs=[input_shape], outputs=[output_shape])\n","    auto.compile(optimizer=optimizers.Adam(0.0001), loss=losses.mean_squared_error, metrics=['mae'])\n","    #auto.summary()\n","    return auto\n","\n","def train_model(model, train_np, validate_np, epoch_size, test_train_np, test_validate_np):\n","    tensorboard = TensorBoard(log_dir='./logs')\n","    model.fit(train_np, validate_np, verbose=1, epochs=epoch_size, shuffle=True, validation_data=(test_train_np, test_validate_np), callbacks=[tensorboard])\n","    \n","def save_predicted(model, save_dir, train_np, validate_np, save_size):\n","    predicted_path = create_dir(save_dir)\n","    predicted_gray = model.predict(train_np)\n","\n","    for count in range(0, save_size):\n","        train_img = train_np[count] * 255\n","        train_img = train_img.astype('int')\n","\n","        pred_img = predicted_gray[count] * 255\n","        pred_img = pred_img.astype('int')\n","\n","        true_img = validate_np[count] * 255\n","        true_img = true_img.astype('int')\n","        \n","        cv2.imwrite(save_path(predicted_path, str(count), '_TR.jpg'), train_img)\n","        cv2.imwrite(save_path(predicted_path, str(count), '_PR.jpg'), pred_img)\n","        cv2.imwrite(save_path(predicted_path, str(count), '_GT.jpg'), true_img)\n","        \n","#-------------------------------------------------------------------------------\n","# Pre/Post Visualization\n","def show_images(image_index, train_np, validate_np, predicted_np=None, rgb_np=None, mode='PRE', model='B2G', row=1, col=4, **kwargs):\n","    figure = plt.figure(figsize=(10,10))\n","    show_img = figure.add_subplot(row, col, 1)\n","    show_img.imshow(train_np[image_index].squeeze(), cmap='gray')\n","    show_img = figure.add_subplot(row, col, 2)\n","    show_img.imshow(validate_np[image_index].squeeze(), cmap='gray')\n","    if mode == 'POST':\n","        show_img = figure.add_subplot(row, col, 3)\n","        show_img.imshow(predicted_np[image_index].squeeze(), cmap='gray')\n","        if model == 'B2RGB':\n","            show_img = figure.add_subplot(row, col, 4)\n","            show_img.imshow(rgb_np[image_index].squeeze())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[0],"colab_type":"code","id":"xcMRi_cjbihm","colab":{}},"source":["# Resize Image\n","square_images(dataset_path, dim_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"StNG12bQbiho","scrolled":true,"colab":{}},"source":["# Prepocess, load image into numpy arrays, and saves data to .npz\n","train_bin, val_gray, _ = load_model_data(resized_train_path, train_path, validate_path, models_path, saved_data, None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kcPA8nWRqAGe","colab":{}},"source":["# Load in preprocessed from .npz\n","\n","#train_bin, val_gray, val_rgb, _, _ = load_saved(os.path.join(models_path, saved_data))\n","#train_bin, test_train_bin, val_gray, test_val_gray, val_rgb, test_val_rgb = train_test_split(train_bin, val_gray, val_rgb, test_size=0.2)\n","train_bin, val_gray, val_rgb, _, _ = load_saved(os.path.join(models_path, saved_data))\n","train_bin, test_train_bin, val_gray, test_val_gray = train_test_split(train_bin, val_gray, test_size=0.2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4ilENjUSCAQR","colab":{}},"source":["#Data Prepocessing (Normalization, augmentation)\n","generator = ImageDataGenerator(rescale=1./255, rotation_range=30,\n","                            width_shift_range=0.1, height_shift_range=0.1, \n","                            shear_range=0.2,zoom_range=0.2,\n","                            horizontal_flip=True, fill_mode='nearest')\n","#Dependent on file structure, each subfolder is a class\n","#Image size is left at defaulted 256x256\n","augmented = generator.flow_from_directory(data_dir, save_to_dir=train_dir,\n","                                         save_format='jpg')\n","#Generate augmentation\n","aug_count = 0\n","aug_size = 100\n","while(aug_count < aug_size):\n","    next(augmented)\n","    aug_count += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[],"colab_type":"code","id":"gBddyK6Rbihq","colab":{}},"source":["# Load images into arrays\n","'''\n","#Testing functions\n","train_arr = load_binary_gray(train_path, 399)\n","validate_arr = load_binary_gray(validate_path, 399)\n","test_train_arr = load_binary_gray(test_train_path, 99)\n","test_val_arr = load_binary_gray(test_val_path, 99)\n","\n","train_arr = test_load(train_path)\n","validate_arr = test_load(validate_path)\n","test_arr = test_load(test_path)\n","\n","# Convert image array into numpy array\n","train_np = np.array(train_arr)\n","validate_np = np.array(validate_arr)\n","test_train_np = np.array(test_train_arr)\n","test_val_np = np.array(test_val_arr)\n","'''\n","train_bin = train_bin.astype('float32')\n","val_gray = val_gray.astype('float32')\n","test_train_bin = test_train_bin.astype('float32')\n","test_val_gray = test_val_gray.astype('float32')\n","#val_rgb = val_rgb.astype('float32')\n","#test_val_rgb = test_val_rgb.astype('float32')\n","\n","# Reshape to include channel dim for grayscale/black and white images\n","train_bin = train_bin.reshape(train_bin.shape[0], dim_size, dim_size, l_channel)\n","val_gray = val_gray.reshape(val_gray.shape[0], dim_size, dim_size, l_channel)\n","test_train_bin = test_train_bin.reshape(test_train_bin.shape[0], dim_size, dim_size, l_channel)\n","test_val_gray = test_val_gray.reshape(test_val_gray.shape[0], dim_size, dim_size, l_channel)\n","#val_rgb = RGB2LAB(val_rg)\n","#test_val_rgb = RGB2LAB(test_val_rgb)\n","\n","# Normalize LAB, L [0,100], ab[-127,127]\n","#train_gray = (val_gray - min(val_gray))/(max(val_gray) - min(val_gray)) * 100\n","t#est_train_gray = (test_val_gray - min(test_val_gray))/(max(test_val_gray) - min(test_val_gray)) * 100\n","\n","\n","# Normalize Binary [0,1]\n","train_bin = train_bin/255\n","val_gray = val_gray/255\n","test_train_bin = test_train_bin/255\n","test_val_gray = test_val_gray/255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"code_folding":[],"colab_type":"code","id":"-Y106wjLbiht","scrolled":true,"colab":{}},"source":["# Check data size, dimensions, and channels\n","print(train_bin.shape)\n","print(train_bin.dtype)\n","print(val_gray.shape)\n","print(val_gray.dtype)\n","print(test_train_bin.shape)\n","print(test_val_gray.shape)\n","\n","# Check dataset images\n","show_images(0, train_bin, val_gray, mode='POST')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tu4Zd4cVwgWU","colab":{}},"source":["# Loads saved architecture and weights\n","auto_BIN2GR = load_model(os.path.join(models_path, \"saved_model-adam-mse-512-dr50-flowers-2.h5\"))\n","#auto_GR2RGB = load_model(os.path.join(models_path, ))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"n5ECmmaTufPQ","colab":{}},"source":["drop_rate = 0.5\n","filters = [16, 32, 64, 128, 256, 512]\n","kernel_sizes = {'encode': 3, 'upsample': 2, 'decode': 3}\n","stride_sizes = {'encode': 1, 'upsample': 2, 'decode': 1}\n","\n","auto_BIN2GR = autoencoder(train_bin.shape[1:], filters, kernel_sizes, stride_sizes, drop_rate)\n","train_model(auto_BIN2GR, train_bin, val_gray, 30, test_train_bin, test_val_gray)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yImwvHToEJUI","colab":{}},"source":["#auto_GR2RGB = autoencoder(train_bin.shape[1:], filters, kernel_sizes, stride_sizes, drop_rate, decoder_activation='tanh')\n","#train_model(auto_GR2RGB, val_gray, val_rgb, 30, test_train_bin, test_val_gray)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2ICVQHyjI4-o","colab":{}},"source":["save_loaded(saved_data, binary=train_bin, grayscale=val_gray)\n","#save_loaded(saved_data, binary=train_bin, grayscale=val_gray, predicted_gray=predict_gray, predicted_rgb=predict_rgb)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2B02GR6Nwgbd","colab":{}},"source":["auto.save(os.path.join(models_path, '{}.h5'.format(save_name)))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HAjp3IvJmSDT","colab_type":"text"},"source":["References:\n","\n","https://github.com/rrupeshh/Auto-Colorization-Of-GrayScale-Image/blob/master/Auto_color.ipynb\n","\n","https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/issues/190"]}]}